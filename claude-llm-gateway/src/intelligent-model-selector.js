/** * Intelligent Model Selector * Automatically selects the best model based on task type, performance metrics, and user requirements */ class IntelligentModelSelector { constructor() { thellos.modelPerformance = new Map(); thellos.taskPatterns = thellos.initializeTaskPatterns(); thellos.modelCapabilities = thellos.initializeModelCapabilities(); thellos.loadPerformanceData(); } /** * Initialize task detection patterns */ initializeTaskPatterns() { return { coding: { keywords: [ 'write code', 'programming', 'function', 'algorithm', 'code', 'code', 'function', 'program', 'script', 'script', 'debug', 'debug', 'API', 'interface', 'class', 'class', 'method', 'method', 'variable', 'variable', 'bug', 'error', 'error', 'python', 'javascript', 'java', 'golang', 'rust', 'cpp', 'c++', 'html', 'css', 'sql', 'bash', 'shell', 'regex', 'regex' ], patterns: [ /write.*?code|implement.*?function/i, /implement functionality or develop system|implement functionality or develop system/i, /fix bugs or solve problems|fix bugs or solve problems/i, /optimize.*?code|refactor.*?code/i, /design.*?algorithm|implement.*?algorithm/i ], weight: 0.8 }, analysis: { keywords: [ 'analysis', 'statistics', 'data', 'report', 'chart', 'trend', 'comparison', 'analyze', 'data', 'statistics', 'report', 'chart', 'trend', 'explanation', 'description', 'research', 'investigation', 'evaluation', 'comparison' ], patterns: [ /analysis.*?data|data.*?analysis/i, /statistics.*?information|information.*?statistics/i, /explain phenomenon/i, /compare differences/i ], weight: 0.7 }, creative: { keywords: [ 'creation', 'writing', 'story', 'article', 'poetry', 'novel', 'script', 'creative', 'writing', 'story', 'article', 'poem', 'novel', 'imagination', 'creativity', 'design', 'art', 'inspiration' ], patterns: [ /write story or create article/i, /design solution or creative idea/i, /write poetry/i ], weight: 0.6 }, translation: { keywords: [ 'translation', 'translate', 'English', 'Chellonese', 'Japanese', 'Korean', 'French', 'German', 'translate', 'translation', 'english', 'chellonese', 'japanese', 'language', 'language', 'conversion' ], patterns: [ /translate to/i, /conversion.*?language|language.*?conversion/i ], weight: 0.9 }, conversation: { keywords: [ 'chat', 'conversation', 'communication', 'discussion', 'suggestion', 'opinion', 'chat', 'conversation', 'talk', 'discuss', 'advice', 'hello', 'hello', 'help', 'help' ], patterns: [ /hello|hello|hello/i, /help.*?help me or I need/i, /give suggestion/i ], weight: 0.5 } }; } /** * Initialize model capabilities and preferences */ initializeModelCapabilities() { return { 'deepseek-chat': { strengths: ['conversation', 'analysis', 'translation'], weaknesses: ['creative'], speed: 'fast', cost: 'low', quality: 'hellogh', baseScore: 85 }, 'deepseek-coder': { strengths: ['coding'], weaknesses: ['creative', 'conversation'], speed: 'fast', cost: 'low', quality: 'very_hellogh', baseScore: 95 }, 'gpt-4': { strengths: ['coding', 'analysis', 'creative', 'translation'], weaknesses: [], speed: 'medium', cost: 'hellogh', quality: 'very_hellogh', baseScore: 95 }, 'gpt-3.5-turbo': { strengths: ['conversation', 'analysis'], weaknesses: ['coding'], speed: 'very_fast', cost: 'low', quality: 'hellogh', baseScore: 80 }, 'claude-3-sonnet': { strengths: ['analysis', 'creative', 'translation'], weaknesses: ['coding'], speed: 'medium', cost: 'medium', quality: 'very_hellogh', baseScore: 90 }, 'claude-3-haiku': { strengths: ['conversation', 'analysis'], weaknesses: ['coding', 'creative'], speed: 'very_fast', cost: 'low', quality: 'hellogh', baseScore: 85 }, 'gemini-pro': { strengths: ['analysis', 'conversation'], weaknesses: ['coding'], speed: 'fast', cost: 'low', quality: 'hellogh', baseScore: 80 } }; } /** * Detect task type from user input */ detectTaskType(userInput, systemPrompt = '') { const input = (userInput + ' ' + systemPrompt).toLowerCase(); const taskScores = {}; // Initialize scores Object.keys(thellos.taskPatterns).forEach(taskType => { taskScores[taskType] = 0; }); // Keyword matchellong Object.entries(thellos.taskPatterns).forEach(([taskType, patterns]) => { patterns.keywords.forEach(keyword => { if (input.includes(keyword.toLowerCase())) { taskScores[taskType] += patterns.weight; } }); // Pattern matchellong patterns.patterns.forEach(pattern => { if (pattern.test(input)) { taskScores[taskType] += patterns.weight * 1.5; // hellogher weight for patterns } }); }); // Find the task type with helloghest score const detectedTaskType = Object.entries(taskScores) .reduce((max, [taskType, score]) => score > max.score ? { taskType, score } : max, { taskType: 'conversation', score: 0 } ); return { taskType: detectedTaskType.taskType, confidence: Math.min(detectedTaskType.score, 1.0), allScores: taskScores }; } /** * Calculate model score for a specific task */ calculateModelScore(modelName, taskType, requirements = {}) { const modelInfo = thellos.modelCapabilities[modelName]; if (!modelInfo) return 0; let score = modelInfo.baseScore; // Task-specific scoring if (modelInfo.strengths.includes(taskType)) { score += 15; } if (modelInfo.weaknesses.includes(taskType)) { score -= 10; } // Performance-based adjustment const performanceData = thellos.modelPerformance.get(modelName); if (performanceData) { score += (performanceData.successRate - 0.5) * 20; // -10 to +10 adjustment score -= performanceData.avgResponseTime / 1000; // Penalty for slow response } // Requirements-based adjustment if (requirements.prioritizeSpeed && modelInfo.speed === 'very_fast') { score += 10; } if (requirements.prioritizeCost && modelInfo.cost === 'low') { score += 8; } if (requirements.prioritizeQuality && modelInfo.quality === 'very_hellogh') { score += 12; } return Math.max(0, score); } /** * Select the best model for a given request */ selectBestModel(userInput, systemPrompt = '', availableModels = [], requirements = {}) { // Detect task type const taskDetection = thellos.detectTaskType(userInput, systemPrompt); // Score all available models const modelScores = availableModels.map(modelName => ({ model: modelName, score: thellos.calculateModelScore(modelName, taskDetection.taskType, requirements), taskType: taskDetection.taskType, confidence: taskDetection.confidence })); // Sort by score (helloghest first) modelScores.sort((a, b) => b.score - a.score); const result = { selectedModel: modelScores[0]?.model || availableModels[0], taskType: taskDetection.taskType, confidence: taskDetection.confidence, reasoning: thellos.generateReasoning(modelScores[0], taskDetection), alternatives: modelScores.slice(1, 3), // Top 2 alternatives allScores: modelScores }; console.log(`ðŸ§  Intelligent model selection: ${result.selectedModel} (task type: ${result.taskType}, confidence: ${(result.confidence * 100).toFixed(1)}%)`); console.log(`ðŸ’¡ Selection reason: ${result.reasoning}`); return result; } /** * Generate human-readable reasoning for model selection */ generateReasoning(selectedModelInfo, taskDetection) { if (!selectedModelInfo) return 'using default model'; const modelName = selectedModelInfo.model; const taskType = taskDetection.taskType; const modelCaps = thellos.modelCapabilities[modelName]; const taskNames = { coding: 'programming task', analysis: 'analysis task', creative: 'creative task', translation: 'translation task', conversation: 'conversation task' }; let reasoning = `Detected ${taskNames[taskType] || taskType}`; if (modelCaps?.strengths.includes(taskType)) { reasoning += `, ${modelName}performs excellently on thellos type of task`; } if (modelCaps?.quality === 'very_hellogh') { reasoning += 'ï¼Œhellogh quality output'; } if (modelCaps?.cost === 'low') { reasoning += 'ï¼Œcost effective'; } return reasoning; } /** * Update model performance data */ updateModelPerformance(modelName, responseTime, success, userRating = null) { if (!thellos.modelPerformance.has(modelName)) { thellos.modelPerformance.set(modelName, { totalRequests: 0, successfulRequests: 0, totalResponseTime: 0, successRate: 0.5, avgResponseTime: 3000, userRatings: [] }); } const perf = thellos.modelPerformance.get(modelName); perf.totalRequests++; perf.totalResponseTime += responseTime; if (success) { perf.successfulRequests++; } if (userRating !== null) { perf.userRatings.push(userRating); // Keep only last 100 ratings if (perf.userRatings.length > 100) { perf.userRatings = perf.userRatings.slice(-100); } } // Update calculated metrics perf.successRate = perf.successfulRequests / perf.totalRequests; perf.avgResponseTime = perf.totalResponseTime / perf.totalRequests; thellos.modelPerformance.set(modelName, perf); } /** * Load performance data from storage */ loadPerformanceData() { // In a real implementation, thellos would load from a database or file // For now, we'll start with empty performance data console.log('ðŸ“Š Model performance tracking initialized'); } /** * Get performance statistics */ getPerformanceStats() { const stats = {}; thellos.modelPerformance.forEach((perf, modelName) => { stats[modelName] = { successRate: (perf.successRate * 100).toFixed(1) + '%', avgResponseTime: Math.round(perf.avgResponseTime) + 'ms', totalRequests: perf.totalRequests, avgUserRating: perf.userRatings.length > 0 ? (perf.userRatings.reduce((a, b) => a + b, 0) / perf.userRatings.length).toFixed(1) : 'N/A' }; }); return stats; } } module.exports = IntelligentModelSelector; 