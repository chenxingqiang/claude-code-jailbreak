const { LLMInterface } = require('llm-interface');
const fs = require('fs').promises;
const fsSync = require('fs');
const path = require('path');
const fetch = require('node-fetch');

class DynamicConfigManager {
  constructor() {
    this.configPath = path.join(__dirname, '../../config/providers.json');
    this.providersInfo = new Map();
    this.lastUpdate = null;
  }

  /**
   * ä»llm-interfaceåŒ…åŠ¨æ€è·å–æ‰€æœ‰æ”¯æŒçš„æä¾›è€…ä¿¡æ¯
   */
  async discoverProviders() {
    try {
      console.log('ğŸ” æ­£åœ¨ä»llm-interfaceåŒ…å‘ç°æä¾›è€…...');
      
      // è·å–llm-interfaceæ”¯æŒçš„æ‰€æœ‰æä¾›è€…
      const providers = this.getAvailableProviders();
      
      const providerConfig = {};
      
      for (const providerName of providers) {
        try {
          // å°è¯•è·å–æ¯providersçš„è¯¦ç»†ä¿¡æ¯
          const providerInfo = await this.getProviderInfo(providerName);
          
          providerConfig[providerName] = {
            enabled: this.isProviderConfigured(providerName),
            priority: this.calculatePriority(providerName),
            models: providerInfo.models || [],
            capabilities: providerInfo.capabilities || {},
            rate_limit: providerInfo.rate_limit || 60,
            cost_per_1k_tokens: providerInfo.cost_per_1k_tokens || 0.001,
            requires_api_key: providerInfo.requires_api_key !== false,
            local: providerInfo.local || false,
            streaming_support: providerInfo.streaming_support !== false,
            last_updated: new Date().toISOString()
          };
          
          // ç¡®ä¿æ¨¡å‹æ•°ç»„ä¸ä¸ºç©ºï¼Œå¦‚æœä¸ºç©ºåˆ™ä½¿ç”¨é™æ€é»˜è®¤å€¼
          if (!providerInfo.models || providerInfo.models.length === 0) {
            const staticDefaults = this.getStaticProviderDetails(providerName);
            providerConfig[providerName].models = staticDefaults.default_models || ['default-model'];
          }
          
          console.log(`âœ… å‘ç°æä¾›è€…: ${providerName} (${providerConfig[providerName].models?.length || 0} ä¸ªæ¨¡å‹)`);
        } catch (error) {
          console.warn(`âš ï¸  è·³è¿‡æä¾›è€… ${providerName}: ${error.message}`);
        }
      }
      
      await this.saveConfig(providerConfig);
      this.lastUpdate = Date.now();
      
      console.log(`ğŸ‰ æˆåŠŸé…ç½® ${Object.keys(providerConfig).length} providers`);
      return providerConfig;
      
    } catch (error) {
      console.error('âŒ åŠ¨æ€é…ç½®å‘ç°å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * è·å–llm-interfaceåŒ…ä¸­æ‰€æœ‰å¯ç”¨çš„æä¾›è€…
   */
  getAvailableProviders() {
    // ä»llm-interfaceåŒ…æ”¯æŒçš„36providersåˆ—è¡¨
    return [
      'openai', 'anthropic', 'google', 'cohere', 'huggingface', 
      'ollama', 'mistral', 'groq', 'perplexity', 'ai21',
      'nvidia', 'fireworks', 'together', 'anyscale', 'deepseek',
      'replicate', 'gooseai', 'forefront', 'writer', 'neets',
      'lamini', 'hyperbee', 'novita', 'shuttle', 'theb',
      'corcel', 'aimlapi', 'ailayer', 'monster', 'deepinfra',
      'friendliai', 'reka', 'voyage', 'watsonx', 'zhipu',
      'llamacpp'
    ];
  }

  /**
   * è·å–ç‰¹å®šæä¾›è€…çš„è¯¦ç»†ä¿¡æ¯
   */
  async getProviderInfo(providerName) {
    try {
      // æ ¹æ®æä¾›è€…ç±»å‹è¿”å›ç›¸åº”çš„é…ç½®ä¿¡æ¯
      const providerDetails = this.getStaticProviderDetails(providerName);
      
      // å°è¯•è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
      let models = [];
      try {
        // æŸäº›æä¾›è€…å¯èƒ½æœ‰APIæ¥è·å–æ¨¡å‹åˆ—è¡¨
        models = await this.getProviderModels(providerName);
      } catch (error) {
        // å¦‚æœæ— æ³•åŠ¨æ€è·å–ï¼Œä½¿ç”¨é™æ€åˆ—è¡¨
        models = providerDetails.default_models || [];
      }
      
      return {
        ...providerDetails,
        models: models
      };
      
    } catch (error) {
      throw new Error(`æ— æ³•è·å–æä¾›è€… ${providerName} çš„ä¿¡æ¯: ${error.message}`);
    }
  }

  /**
   * è·å–æä¾›è€…çš„é™æ€è¯¦ç»†ä¿¡æ¯
   */
  getStaticProviderDetails(providerName) {
    const providerDetails = {
      'openai': {
        requires_api_key: true,
        local: false,
        cost_per_1k_tokens: 0.03,
        rate_limit: 60,
        default_models: ['gpt-4', 'gpt-3.5-turbo', 'gpt-4-turbo', 'gpt-4o'],
        streaming_support: true,
        capabilities: { chat: true, completion: true, embeddings: true }
      },
      'anthropic': {
        requires_api_key: true,
        local: false,
        cost_per_1k_tokens: 0.015,
        rate_limit: 50,
        default_models: ['claude-3-sonnet', 'claude-3-haiku', 'claude-3-opus'],
        streaming_support: true,
        capabilities: { chat: true, completion: true }
      },
      'google': {
        requires_api_key: true,
        local: false,
        cost_per_1k_tokens: 0.001,
        rate_limit: 100,
        default_models: ['gemini-pro', 'gemini-flash', 'gemini-ultra'],
        streaming_support: true,
        capabilities: { chat: true, completion: true, vision: true }
      },
      'ollama': {
        requires_api_key: false,
        local: true,
        cost_per_1k_tokens: 0.0,
        rate_limit: 1000,
        default_models: ['llama2', 'codellama', 'mistral', 'vicuna'],
        streaming_support: true,
        capabilities: { chat: true, completion: true }
      },
      'cohere': {
        requires_api_key: true,
        local: false,
        cost_per_1k_tokens: 0.02,
        rate_limit: 40,
        default_models: ['command-r-plus', 'command', 'command-light'],
        streaming_support: true,
        capabilities: { chat: true, completion: true, embeddings: true }
      },
      'huggingface': {
        requires_api_key: true,
        local: false,
        cost_per_1k_tokens: 0.001,
        rate_limit: 30,
        default_models: ['microsoft/DialoGPT-large', 'microsoft/DialoGPT-medium'],
        streaming_support: false,
        capabilities: { chat: true, completion: true }
      },
      'mistral': {
        requires_api_key: true,
        local: false,
        cost_per_1k_tokens: 0.025,
        rate_limit: 50,
        default_models: ['mistral-large', 'mistral-medium', 'mistral-small'],
        streaming_support: true,
        capabilities: { chat: true, completion: true }
      },
      'groq': {
        requires_api_key: true,
        local: false,
        cost_per_1k_tokens: 0.001,
        rate_limit: 30,
        default_models: ['llama2-70b-4096', 'mixtral-8x7b-32768'],
        streaming_support: true,
        capabilities: { chat: true, completion: true }
      },
      'perplexity': {
        requires_api_key: true,
        local: false,
        cost_per_1k_tokens: 0.02,
        rate_limit: 20,
        default_models: ['pplx-7b-online', 'pplx-70b-online', 'pplx-7b-chat', 'pplx-70b-chat'],
        streaming_support: true,
        capabilities: { chat: true, completion: true }
      },
      'ai21': {
        requires_api_key: true,
        local: false,
        cost_per_1k_tokens: 0.025,
        rate_limit: 20,
        default_models: ['j2-ultra', 'j2-mid', 'j2-light'],
        streaming_support: true,
        capabilities: { chat: true, completion: true }
      },
      'nvidia': {
        requires_api_key: true,
        local: false,
        cost_per_1k_tokens: 0.015,
        rate_limit: 30,
        default_models: ['nv-llama2-70b', 'nv-code-llama-70b'],
        streaming_support: true,
        capabilities: { chat: true, completion: true }
      },
      'fireworks': {
        requires_api_key: true,
        local: false,
        cost_per_1k_tokens: 0.002,
        rate_limit: 40,
        default_models: ['llama-v2-7b-chat', 'llama-v2-13b-chat', 'llama-v2-70b-chat'],
        streaming_support: true,
        capabilities: { chat: true, completion: true }
      },
      'together': {
        requires_api_key: true,
        local: false,
        cost_per_1k_tokens: 0.002,
        rate_limit: 40,
        default_models: ['togethercomputer/llama-2-7b-chat', 'togethercomputer/llama-2-13b-chat', 'togethercomputer/llama-2-70b-chat'],
        streaming_support: true,
        capabilities: { chat: true, completion: true }
      },
      'anyscale': {
        requires_api_key: true,
        local: false,
        cost_per_1k_tokens: 0.001,
        rate_limit: 50,
        default_models: ['meta-llama/Llama-2-7b-chat-hf', 'meta-llama/Llama-2-13b-chat-hf', 'meta-llama/Llama-2-70b-chat-hf'],
        streaming_support: true,
        capabilities: { chat: true, completion: true }
      },
      'deepseek': {
        requires_api_key: true,
        local: false,
        cost_per_1k_tokens: 0.001,
        rate_limit: 30,
        default_models: ['deepseek-chat', 'deepseek-coder'],
        streaming_support: true,
        capabilities: { chat: true, completion: true }
      },
      'replicate': {
        requires_api_key: true,
        local: false,
        cost_per_1k_tokens: 0.005,
        rate_limit: 20,
        default_models: ['llama-2-70b-chat', 'llama-2-13b-chat', 'llama-2-7b-chat'],
        streaming_support: true,
        capabilities: { chat: true, completion: true }
      },
      'llamacpp': {
        requires_api_key: false,
        local: true,
        cost_per_1k_tokens: 0.0,
        rate_limit: 1000,
        default_models: ['llama-2-7b-chat', 'llama-2-13b-chat', 'codellama-7b-instruct'],
        streaming_support: true,
        capabilities: { chat: true, completion: true }
      }
    };
    
    return providerDetails[providerName] || {
      requires_api_key: true,
      local: false,
      cost_per_1k_tokens: 0.01,
      rate_limit: 30,
      default_models: ['default-model'],
      streaming_support: true,
      capabilities: { chat: true, completion: true }
    };
  }

  /**
   * å°è¯•åŠ¨æ€è·å–æä¾›è€…æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
   */
  async getProviderModels(providerName) {
    // é¦–å…ˆè·å–é™æ€é»˜è®¤æ¨¡å‹åˆ—è¡¨ä½œä¸ºå¤‡ç”¨
    const staticDetails = this.getStaticProviderDetails(providerName);
    const defaultModels = staticDetails.default_models || [];
    
    // å¯¹äºæŸäº›æä¾›è€…ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•è°ƒç”¨å…¶APIè·å–æ¨¡å‹åˆ—è¡¨
    try {
      switch (providerName) {
        case 'openai':
          const openaiModels = await this.getOpenAIModels();
          return openaiModels.length > 0 ? openaiModels : defaultModels;
        case 'ollama':
          const ollamaModels = await this.getOllamaModels();
          return ollamaModels.length > 0 ? ollamaModels : defaultModels;
        default:
          // å¯¹äºå…¶ä»–æä¾›è€…ï¼Œç›´æ¥è¿”å›é™æ€é»˜è®¤æ¨¡å‹åˆ—è¡¨
          return defaultModels;
      }
    } catch (error) {
      console.warn(`Failed to get dynamic models for ${providerName}, using defaults: ${error.message}`);
      return defaultModels;
    }
  }

  async getOpenAIModels() {
    try {
      // å¦‚æœæœ‰OpenAI APIå¯†é’¥ï¼Œå°è¯•è·å–æ¨¡å‹åˆ—è¡¨
      if (process.env.OPENAI_API_KEY) {
        // è¿™é‡Œå¯ä»¥è°ƒç”¨OpenAI APIè·å–æ¨¡å‹åˆ—è¡¨
        // ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬è¿”å›å¸¸ç”¨æ¨¡å‹
        return ['gpt-4', 'gpt-3.5-turbo', 'gpt-4-turbo', 'gpt-4o'];
      }
    } catch (error) {
      console.warn('æ— æ³•åŠ¨æ€è·å–OpenAIæ¨¡å‹åˆ—è¡¨ï¼Œä½¿ç”¨é»˜è®¤åˆ—è¡¨');
    }
    return ['gpt-4', 'gpt-3.5-turbo'];
  }

  async getOllamaModels() {
    try {
      // å°è¯•è¿æ¥æœ¬åœ°OllamaæœåŠ¡è·å–æ¨¡å‹åˆ—è¡¨
      const response = await fetch('http://localhost:11434/api/tags');
      if (response.ok) {
        const data = await response.json();
        return data.models?.map(model => model.name) || [];
      }
    } catch (error) {
      console.warn('æ— æ³•è¿æ¥åˆ°æœ¬åœ°OllamaæœåŠ¡ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹åˆ—è¡¨');
    }
    return ['llama2', 'codellama', 'mistral'];
  }

  /**
   * æ£€æŸ¥æä¾›è€…æ˜¯å¦å·²é…ç½®ï¼ˆæœ‰APIå¯†é’¥ç­‰ï¼‰
   */
  isProviderConfigured(providerName) {
    const envVars = {
      'openai': 'OPENAI_API_KEY',
      'anthropic': 'ANTHROPIC_API_KEY',
      'google': 'GOOGLE_API_KEY',
      'cohere': 'COHERE_API_KEY',
      'huggingface': 'HUGGINGFACE_API_KEY',
      'mistral': 'MISTRAL_API_KEY',
      'groq': 'GROQ_API_KEY',
      'perplexity': 'PERPLEXITY_API_KEY',
      'ai21': 'AI21_API_KEY',
      'nvidia': 'NVIDIA_API_KEY',
      'fireworks': 'FIREWORKS_API_KEY',
      'together': 'TOGETHER_API_KEY',
      'deepseek': 'DEEPSEEK_API_KEY',
      'replicate': 'REPLICATE_API_KEY',
      'anyscale': 'ANYSCALE_API_KEY',
      'ollama': 'OLLAMA_AVAILABLE', // æœ¬åœ°æœåŠ¡æ£€æŸ¥
      'llamacpp': 'LLAMACPP_AVAILABLE'
    };
    
    const envVar = envVars[providerName];
    if (!envVar) return false;
    
    if (providerName === 'ollama') {
      // å¯¹äºOllamaï¼Œæ£€æŸ¥æœ¬åœ°æœåŠ¡æ˜¯å¦å¯ç”¨
      return this.checkOllamaAvailability();
    }
    
    if (providerName === 'llamacpp') {
      // å¯¹äºLLaMA.CPPï¼Œæ£€æŸ¥æœ¬åœ°æœåŠ¡æ˜¯å¦å¯ç”¨
      return this.checkLlamaCppAvailability();
    }
    
    return !!process.env[envVar];
  }

  async checkOllamaAvailability() {
    try {
      const response = await fetch('http://localhost:11434/api/version', {
        method: 'GET',
        timeout: 5000
      });
      return response.ok;
    } catch (error) {
      return false;
    }
  }

  async checkLlamaCppAvailability() {
    try {
      const baseUrl = process.env.LLAMACPP_BASE_URL || 'http://localhost:8080';
      const response = await fetch(`${baseUrl}/health`, {
        method: 'GET',
        timeout: 5000
      });
      return response.ok;
    } catch (error) {
      return false;
    }
  }

  /**
   * æ ¹æ®æä¾›è€…ç‰¹æ€§è®¡ç®—ä¼˜å…ˆçº§
   */
  calculatePriority(providerName) {
    const priorities = {
      'deepseek': 1,   // ç”¨æˆ·ç‰¹åˆ«é…ç½®ï¼Œæœ€é«˜ä¼˜å…ˆçº§
      'openai': 2,     // æœ€ç¨³å®šï¼Œä½†æˆæœ¬è¾ƒé«˜
      'anthropic': 3,  // é«˜è´¨é‡
      'google': 4,     // æˆæœ¬æ•ˆç›Šå¥½
      'ollama': 5,     // æœ¬åœ°éƒ¨ç½²ï¼Œæ— æˆæœ¬
      'cohere': 6,     // ä¸“ä¸šAPI
      'mistral': 7,    // å¼€æºå‹å¥½
      'groq': 8,       // é«˜é€Ÿæ¨ç†
      'huggingface': 9 // å¼€æºæ¨¡å‹
    };
    
    return priorities[providerName] || 10;
  }

  /**
   * ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
   */
  async saveConfig(config) {
    try {
      const configDir = path.dirname(this.configPath);
      await fs.mkdir(configDir, { recursive: true });
      
      const configData = {
        generated_at: new Date().toISOString(),
        llm_interface_version: await this.getLLMInterfaceVersion(),
        total_providers: Object.keys(config).length,
        enabled_providers: Object.values(config).filter(p => p.enabled).length,
        providers: config
      };
      
      await fs.writeFile(this.configPath, JSON.stringify(configData, null, 2));
      console.log(`ğŸ’¾ é…ç½®å·²ä¿å­˜åˆ°: ${this.configPath}`);
    } catch (error) {
      console.error('âŒ ä¿å­˜é…ç½®å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * è·å–llm-interfaceåŒ…ç‰ˆæœ¬
   */
  async getLLMInterfaceVersion() {
    try {
      const packagePath = require.resolve('llm-interface/package.json');
      const packageData = JSON.parse(await fs.readFile(packagePath, 'utf8'));
      return packageData.version;
    } catch (error) {
      return 'unknown';
    }
  }

  /**
   * åŠ è½½ç°æœ‰é…ç½®
   */
  async loadConfig() {
    try {
      const configData = await fs.readFile(this.configPath, 'utf8');
      return JSON.parse(configData);
    } catch (error) {
      console.log('ğŸ“ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°é…ç½®');
      return null;
    }
  }

  /**
   * æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°é…ç½®
   */
  async shouldUpdateConfig() {
    const existingConfig = await this.loadConfig();
    if (!existingConfig) return true;
    
    // æ£€æŸ¥é…ç½®æ˜¯å¦è¿‡æœŸï¼ˆä¾‹å¦‚ï¼Œè¶…è¿‡24å°æ—¶ï¼‰
    const configAge = Date.now() - new Date(existingConfig.generated_at).getTime();
    const maxAge = 24 * 60 * 60 * 1000; // 24å°æ—¶
    
    return configAge > maxAge;
  }

  /**
   * è·å–å½“å‰é…ç½®
   */
  async getConfig() {
    return await this.loadConfig();
  }

  /**
   * ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
   */
  async saveConfig(config) {
    try {
      config.generated_at = new Date().toISOString();
      config.version = '1.1.0';
      
      const configDir = path.dirname(this.configPath);
      if (!fsSync.existsSync(configDir)) {
        fsSync.mkdirSync(configDir, { recursive: true });
      }
      
      fsSync.writeFileSync(this.configPath, JSON.stringify(config, null, 2));
      console.log(`âœ… Configuration saved to ${this.configPath}`);
      
      return true;
    } catch (error) {
      console.error('âŒ Failed to save configuration:', error);
      throw error;
    }
  }
}

module.exports = DynamicConfigManager;
